{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd79e316",
   "metadata": {},
   "source": [
    "# 모듈 선택 및 데이터 로드와 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "624506dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "월간 데이콘 뉴스 토픽 분류 AI 경진대회\n",
    "- 목적 : 한국어 뉴스 헤드라인을 이용하여, 뉴스의 주제를 분류하는 알고리즘 개발\n",
    "- 심사 기준 : Accuracy\n",
    "- 1차 평가(Public Score): 테스트 데이터 중 랜덤 샘플 된 50%로 채점, 대회 기간 중 공개\n",
    "- 2차 평가(Private Score): 나머지 50 % 테스트 데이터로 채점, 대회 종료 직후 공개\n",
    "- 최종 순위는 선택된 파일 중에서 채점되므로, 참가자는 제출 창에서 자신이 최종적으로 채점 받고 싶은 파일 2개를 선택해야 함\n",
    "- 1일 최대 제출 횟수: 3회\n",
    "- 사용 가능 언어: Python, R\n",
    "- 모델 학습에서 검증 혹은 평가 데이터셋 활용시(Data Leakage 등) 실격\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib\n",
    "import re\n",
    "import tqdm as tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, SimpleRNN, GRU, Bidirectional, LSTM, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# pd.set_option(\"display.max_seq_items\", None)\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "# label 유형-극성-시제-확실성 이 Target\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0328a57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16541, 7), (7090, 2), (7090, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd332e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>문장</th>\n",
       "      <th>유형</th>\n",
       "      <th>극성</th>\n",
       "      <th>시제</th>\n",
       "      <th>확실성</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>미래</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-미래-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003</td>\n",
       "      <td>서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00004</td>\n",
       "      <td>익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                                 문장   유형  극성  \\\n",
       "0  TRAIN_00000              0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.  사실형  긍정   \n",
       "1  TRAIN_00001  이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...  사실형  긍정   \n",
       "2  TRAIN_00002  정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...  사실형  긍정   \n",
       "3  TRAIN_00003  서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...  사실형  긍정   \n",
       "4  TRAIN_00004           익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.  사실형  긍정   \n",
       "\n",
       "   시제 확실성         label  \n",
       "0  현재  확실  사실형-긍정-현재-확실  \n",
       "1  과거  확실  사실형-긍정-과거-확실  \n",
       "2  미래  확실  사실형-긍정-미래-확실  \n",
       "3  과거  확실  사실형-긍정-과거-확실  \n",
       "4  현재  확실  사실형-긍정-현재-확실  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91315a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(사실형    0.819660\n",
       " 추론형    0.130041\n",
       " 대화형    0.034762\n",
       " 예측형    0.015537\n",
       " Name: 유형, dtype: float64,\n",
       " 긍정    0.954779\n",
       " 부정    0.034158\n",
       " 미정    0.011063\n",
       " Name: 극성, dtype: float64,\n",
       " 과거    0.485581\n",
       " 현재    0.415090\n",
       " 미래    0.099329\n",
       " Name: 시제, dtype: float64,\n",
       " 확실     0.918445\n",
       " 불확실    0.081555\n",
       " Name: 확실성, dtype: float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"유형\"].value_counts(1), train[\"극성\"].value_counts(1), train[\"시제\"].value_counts(1), train[\"확실성\"].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe2d50ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID         label\n",
       "0  TEST_0000  추론형-긍정-현재-확실\n",
       "1  TEST_0001  추론형-긍정-현재-확실\n",
       "2  TEST_0002  추론형-긍정-현재-확실\n",
       "3  TEST_0003  추론형-긍정-현재-확실\n",
       "4  TEST_0004  추론형-긍정-현재-확실"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbb9b2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n유형 컬럼의 포인트\\n - 유형은 주로 맨 뒤 단어와 %가 키 포인트라고 판단\\n \\n극성 컬럼의 포인트\\n - 유형과 거의 동일함, %자 의미 없어서 제거\\n \\n시제 컬럼의 포인트\\n - 유형과 거의 동일함, 과거는 \"됐다, 되었다\"와 같이\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "유형 컬럼의 포인트\n",
    " - 유형은 주로 맨 뒤 단어와 %가 키 포인트라고 판단\n",
    " \n",
    "극성 컬럼의 포인트\n",
    " - 유형과 거의 동일함, %자 의미 없어서 제거\n",
    " \n",
    "시제 컬럼의 포인트\n",
    " - 유형과 거의 동일함, 과거는 \"됐다, 되었다\"와 같이\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "194ba63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...\n",
       "3        서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...\n",
       "8            이번 서비스에는 네이버가 자체 개발한 초대규모 AI 하이퍼클로바 기술이 적용됐다.\n",
       "14       이어 ＂개별 상황에 어떻게 응대해야 할 것인지도 모호한 상황＂이라며 ＂이 같은 부분...\n",
       "15       사우스포게임즈가 개발한 ＇스컬＇의 경우도 지난해 부산인디커넥트 페스티벌, 글로벌인디...\n",
       "                               ...                        \n",
       "16532    국토교통부에 따르면 4월 기준 서울 아파트 미분양 물량은 360가구로 3월(180가...\n",
       "16536    ＇신동덤＇은 ＇신비한 동물사전＇과 ＇해리 포터＇ 시리즈를 잇는 마법 어드벤처물로, ...\n",
       "16537    수족냉증은 어릴 때부터 심했으며 관절은 어디 한 곳이 아니고 목, 어깨, 팔꿈치, ...\n",
       "16538    김금희 소설가는 ＂계약서 조정이 그리 어려운가 작가를 격려한다면서 그런 문구 하나 ...\n",
       "16539    1만명이 넘는 방문자수를 기록한 이번 전시회는 총 77개 작품을 넥슨 사옥을 그대로...\n",
       "Name: 문장, Length: 8032, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 3 8 14 15 16532 16536 16537\n",
    "\n",
    "train[train[\"시제\"] == \"과거\"][\"문장\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ea6261f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.\n",
       "4                 익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.\n",
       "5        이같은 변화를 포함해 올해 종부세 과세 대상은 당초 21만4000명에서 12만100...\n",
       "6        수수꽃다리과로 북한에서 주로 많이 서식한다는 수수꽃다리, 남한의 대표적 라일락으로 ...\n",
       "7        가장 최근에 있었던, OTT 예능 프로그램 출연으로 일약 스타덤에 올랐던 한 인플루...\n",
       "                               ...                        \n",
       "16531    국가의 허리인 중산층이 붕괴하고 있지만, 한국의 중산층 통계는 국민이 체감하는 중산...\n",
       "16533    계약직으로 근무했던 초단시간 근로자의 일상과 도서관이라는 작은 사회를 통해 우리 사...\n",
       "16534    뒷좌석에서 동승자나 별도로 안전하게 보관할 수 있는 애견가방 등을 준비하는 게 좋으...\n",
       "16535    이에 따라 대형 콘서트부터 야외 페스티벌, 실내 공연 등 연이어 오픈 소식이 들려오...\n",
       "16540                                        《목민심서》의 내용이다.\n",
       "Name: 문장, Length: 6866, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train[\"시제\"] == \"현재\"][\"문장\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5a7fba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2        정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...\n",
       "12       비가 내리는 지역에서는 돌풍과 함께 천둥·번개가 치고 일부 지역에선 우박이 떨어지는...\n",
       "39                사람 친구는 어느 한쪽에 애인이 생기면 끊어주는 게 쌈빡한 예의 아닐까.\n",
       "48       계약서 작성이나 분쟁 해결 과정에서 이런 원칙과 기준을 조금이라도 알면 큰 도움이 ...\n",
       "52                         한빛소프트는 올해도 리폼 이벤트를 계속 진행할 계획이다.\n",
       "                               ...                        \n",
       "16504            채권 만기는 내년 1월로, 이를 상환하지 못하면 디폴트 위기를 맞게 된다.\n",
       "16507     하지만 누군가 나눔과 상생이란 착한 바이러스를 퍼뜨리기 시작한다면 그래도 희망이 있다.\n",
       "16518       이에 삼양식품이 수출 비중이 높은 만큼 달러 강세의 수혜를 입을 것이라는 전망이다.\n",
       "16520    불안한 10대들과 공감하며 소통했던 라디오 DJ의 모습부터 사회적 문제 제기와 해결...\n",
       "16528    5월에는 인천-프랑크푸르트 노선을 5월28일부터 주 4회에서 주 5회로 증편하고, ...\n",
       "Name: 문장, Length: 1643, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train[\"시제\"] == \"미래\"][\"문장\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df63faa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2977f126",
   "metadata": {},
   "source": [
    "# 데이터 전처리 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1980016d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       사실형\n",
       "1       사실형\n",
       "2       사실형\n",
       "3       사실형\n",
       "4       사실형\n",
       "       ... \n",
       "7085    사실형\n",
       "7086    사실형\n",
       "7087    사실형\n",
       "7088    사실형\n",
       "7089    사실형\n",
       "Name: 유형, Length: 7090, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_1 = \"유형\"\n",
    "label_2 = \"극성\"\n",
    "label_3 = \"시제\"\n",
    "label_4 = \"확실성\"\n",
    "\n",
    "# \"유형\" 컬럼 해결\n",
    "\n",
    "df_1 = train[\"문장\"]\n",
    "\n",
    "# text 자리에 train[\"문장\"]\n",
    "# 문장 전처리 함수\n",
    "def label_1_data(text):\n",
    "    # 전부 소문자 처리\n",
    "    text = text.map(lambda x : x.lower())\n",
    "    # 한글, 영어, 공백, % 제외하고 전부 삭제\n",
    "    text = text.map(lambda x : re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 a-z%]\", \"\", x))\n",
    "    # 공백 여러 개 삭제\n",
    "    text = text.map(lambda x : re.sub(\"[\\s]\", \" \", x))\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_1 = label_1_data(df_1)\n",
    "\n",
    "\n",
    "# 불용어 제거\n",
    "def remove_stopwords(text):\n",
    "    tokens = text.split(' ')\n",
    "    stops = [\"정부가\", \"정부는\", \"정부에서\", \"이\", \"같은\", \"함께\", \"주\", \"이어\", \n",
    "            \"앞으로\", \"이번\", \"저번\", \"즉시\", \"이같은\", \"년\", \"월\", \"일\", \"및\", \"더\", \n",
    "            \"마치\", \"그리고\", \"그러나\", \"하지만\", \"시\", \"분\", \"초\", \"미국은\", \"미국의\", \"그래도\", \n",
    "            \"미국\", \"중국\", \"중국은\", \"중국의\", \"또\", \"또한\", \"그\", \"그래야\", \"오는\", \"이외\", \n",
    "            \"서울\", \"서울은\", \"서울의\", \"서울이\", \"서울에서\", \"한국\", \"한국형\", \"한국은\", \n",
    "            \"한국의\", \"총\", \"개\", \"등\", \"서울시는\", \"서울시\", \"서울시에서\", \"수출\", \"수입\", \"국가의\", \"국가\", \"국가는\"]\n",
    "    meaningful_words = [w for w in tokens if not w in stops]\n",
    "    \n",
    "    return ' '.join(meaningful_words)\n",
    "\n",
    "df_1 = df_1.map(lambda x : remove_stopwords(x))\n",
    "\n",
    "df_1_y = train[label_1]\n",
    "df_1_y = pd.get_dummies(df_1_y)\n",
    "\n",
    "# TF-IDF로 적용 / min은 %가 값이 두개 잡히는 경계를 기준\n",
    "# max는 지니계수의 개념과 같이 생각하면 0.5 정도가 적당하다고 판단\n",
    "tfvect = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 3), min_df=0.01, max_df=0.5)\n",
    "df_1_type = tfvect.fit_transform(df_1)\n",
    "vocab = tfvect.get_feature_names_out()\n",
    "df_dtm = pd.DataFrame(df_1_type.toarray(), columns=vocab)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_dtm, df_1_y, random_state=42, \n",
    "                                                   stratify=df_1_y, test_size=0.1)\n",
    "# X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "df_sub = test[\"문장\"]\n",
    "df_sub = label_1_data(df_sub)\n",
    "df_sub = df_sub.map(lambda x : remove_stopwords(x))\n",
    "df_sub_type = tfvect.transform(df_sub)\n",
    "df_sub_dtm = pd.DataFrame(df_sub_type.toarray(), columns=vocab)\n",
    "\n",
    "y_pred = model.predict(df_sub_dtm)\n",
    "# (y_test == y_pred).mean()\n",
    "\n",
    "# 대화형 - 사실형 - 예측형 - 추론형\n",
    "\n",
    "y_predict = pd.DataFrame(y_pred)\n",
    "\n",
    "# 원핫인코딩 값 되돌리는 함수\n",
    "def one_hot_back(y_predict):\n",
    "    y_predict[\"유형\"] = None\n",
    "    for i in range(len(y_predict[\"유형\"])):\n",
    "        if y_predict.loc[i, 0] == 1:\n",
    "            y_predict.loc[i, \"유형\"] = \"대화형\"\n",
    "        if y_predict.loc[i, 1] == 1:\n",
    "            y_predict.loc[i, \"유형\"] = \"사실형\"\n",
    "        if y_predict.loc[i, 2] == 1:\n",
    "            y_predict.loc[i, \"유형\"] = \"예측형\"\n",
    "        if y_predict.loc[i, 3] == 1:\n",
    "            y_predict.loc[i, \"유형\"] = \"추론형\"\n",
    "            \n",
    "    return y_predict\n",
    "\n",
    "Answer_1 = one_hot_back(y_predict)\n",
    "Answer_1 = Answer_1[\"유형\"]\n",
    "Answer_1\n",
    "# (y_test == y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4671e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       긍정\n",
       "1       긍정\n",
       "2       긍정\n",
       "3       긍정\n",
       "4       긍정\n",
       "        ..\n",
       "7085    긍정\n",
       "7086    긍정\n",
       "7087    긍정\n",
       "7088    긍정\n",
       "7089    긍정\n",
       "Name: 극성, Length: 7090, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"극성\" 컬럼 해결\n",
    "\n",
    "df_2 = train[\"문장\"]\n",
    "\n",
    "# text 자리에 train[\"문장\"]\n",
    "# 문장 전처리 함수\n",
    "def label_2_data(text):\n",
    "    # 전부 소문자 처리\n",
    "    text = text.map(lambda x : x.lower())\n",
    "    # 한글, 영어, 공백, % 제외하고 전부 삭제\n",
    "    text = text.map(lambda x : re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 a-z]\", \"\", x))\n",
    "    # 공백 여러 개 삭제\n",
    "    text = text.map(lambda x : re.sub(\"[\\s]\", \" \", x))\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_2 = label_2_data(df_2)\n",
    "\n",
    "\n",
    "# 불용어 제거\n",
    "def remove_stopwords(text):\n",
    "    tokens = text.split(' ')\n",
    "    stops = [\"정부가\", \"정부는\", \"정부에서\", \"이\", \"같은\", \"함께\", \"주\", \"이어\", \n",
    "            \"앞으로\", \"이번\", \"저번\", \"즉시\", \"이같은\", \"년\", \"월\", \"일\", \"및\", \"더\", \n",
    "            \"마치\", \"그리고\", \"그러나\", \"하지만\", \"시\", \"분\", \"초\", \"미국은\", \"미국의\", \n",
    "            \"미국\", \"중국\", \"중국은\", \"중국의\", \"또\", \"또한\", \"그\", \"그래야\", \"오는\", \"이외\", \n",
    "            \"서울\", \"서울은\", \"서울의\", \"서울이\", \"서울에서\", \"한국\", \"한국형\", \"한국은\", \n",
    "            \"한국의\", \"총\", \"개\", \"등\", \"서울시는\", \"서울시\", \"서울시에서\", \"수출\", \"수입\", \"국가의\", \"국가\", \"국가는\"]\n",
    "    meaningful_words = [w for w in tokens if not w in stops]\n",
    "    \n",
    "    return ' '.join(meaningful_words)\n",
    "\n",
    "df_2 = df_2.map(lambda x : remove_stopwords(x))\n",
    "\n",
    "df_2_y = train[label_2]\n",
    "df_2_y = pd.get_dummies(df_2_y)\n",
    "\n",
    "\n",
    "# TF-IDF로 적용 / min은 %가 값이 두개 잡히는 경계를 기준\n",
    "# max는 지니계수의 개념과 같이 생각하면 0.5 정도가 적당하다고 판단\n",
    "tfvect = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 3), min_df=0.01, max_df=0.5)\n",
    "df_2_type = tfvect.fit_transform(df_2)\n",
    "vocab = tfvect.get_feature_names_out()\n",
    "df_dtm = pd.DataFrame(df_2_type.toarray(), columns=vocab)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_dtm, df_2_y, random_state=42, \n",
    "                                                   stratify=df_2_y, test_size=0.1)\n",
    "# X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "df_sub = test[\"문장\"]\n",
    "df_sub = label_2_data(df_sub)\n",
    "df_sub = df_sub.map(lambda x : remove_stopwords(x))\n",
    "df_sub_type = tfvect.transform(df_sub)\n",
    "df_sub_dtm = pd.DataFrame(df_sub_type.toarray(), columns=vocab)\n",
    "\n",
    "y_pred = model.predict(df_sub_dtm)\n",
    "\n",
    "# (y_test == y_pred).mean()\n",
    "\n",
    "#긍정 - 미정 - 부정\n",
    "\n",
    "y_predict = pd.DataFrame(y_pred)\n",
    "\n",
    "# 원핫인코딩 값 되돌리는 함수\n",
    "def one_hot_back(y_predict):\n",
    "    y_predict[\"극성\"] = None\n",
    "    for i in range(len(y_predict[\"극성\"])):\n",
    "        if y_predict.loc[i, 0] == 1:\n",
    "            y_predict.loc[i, \"극성\"] = \"긍정\"\n",
    "        if y_predict.loc[i, 1] == 1:\n",
    "            y_predict.loc[i, \"극성\"] = \"미정\"\n",
    "        if y_predict.loc[i, 2] == 1:\n",
    "            y_predict.loc[i, \"극성\"] = \"부정\"\n",
    "            \n",
    "    return y_predict\n",
    "\n",
    "Answer_2 = one_hot_back(y_predict)\n",
    "Answer_2 = Answer_2[\"극성\"]\n",
    "Answer_2\n",
    "# (y_test == y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d31edefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       현재\n",
       "1       현재\n",
       "2       과거\n",
       "3       현재\n",
       "4       과거\n",
       "        ..\n",
       "7085    현재\n",
       "7086    현재\n",
       "7087    현재\n",
       "7088    현재\n",
       "7089    현재\n",
       "Name: 시제, Length: 7090, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"시제\" 컬럼 해결\n",
    "\n",
    "df_3 = train[\"문장\"]\n",
    "\n",
    "# text 자리에 train[\"문장\"]\n",
    "# 문장 전처리 함수\n",
    "def label_3_data(text):\n",
    "    # 전부 소문자 처리\n",
    "    text = text.map(lambda x : x.lower())\n",
    "    # 한글, 영어, 공백, % 제외하고 전부 삭제\n",
    "    text = text.map(lambda x : re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", x))\n",
    "    # 공백 여러 개 삭제\n",
    "    text = text.map(lambda x : re.sub(\"[\\s]\", \" \", x))\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_3 = label_3_data(df_3)\n",
    "\n",
    "\n",
    "# 불용어 제거\n",
    "def remove_stopwords(text):\n",
    "    tokens = text.split(' ')\n",
    "    stops = [\"정부가\", \"정부는\", \"정부에서\", \"이\", \"같은\", \"함께\", \"주\", \n",
    "            \"년\", \"월\", \"일\", \"및\", \"더\", \"수출\", \"수입\", \"국가의\", \"국가\", \"국가는\", \n",
    "            \"마치\", \"그리고\", \"그러나\", \"하지만\", \"시\", \"분\", \"초\", \"미국은\", \"미국의\", \"그래도\", \n",
    "            \"미국\", \"중국\", \"중국은\", \"중국의\", \"또\", \"또한\", \"그\", \"그래야\", \"오는\", \"이외\", \n",
    "            \"서울\", \"서울은\", \"서울의\", \"서울이\", \"서울에서\", \"한국\", \"한국형\", \"한국은\", \n",
    "            \"한국의\", \"총\", \"개\", \"등\", \"서울시는\", \"서울시\", \"서울시에서\"]\n",
    "    meaningful_words = [w for w in tokens if not w in stops]\n",
    "    \n",
    "    return ' '.join(meaningful_words)\n",
    "\n",
    "df_3 = df_3.map(lambda x : remove_stopwords(x))\n",
    "\n",
    "df_3_y = train[label_3]\n",
    "df_3_y = pd.get_dummies(df_3_y)\n",
    "\n",
    "# TF-IDF로 적용 / min은 %가 값이 두개 잡히는 경계를 기준\n",
    "# max는 지니계수의 개념과 같이 생각하면 0.5 정도가 적당하다고 판단\n",
    "tfvect = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 3), min_df=0.01, max_df=0.5)\n",
    "df_3_type = tfvect.fit_transform(df_3)\n",
    "vocab = tfvect.get_feature_names_out()\n",
    "df_dtm = pd.DataFrame(df_3_type.toarray(), columns=vocab)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_dtm, df_3_y, random_state=42, \n",
    "                                                   stratify=df_3_y, test_size=0.1)\n",
    "# X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "df_sub = test[\"문장\"]\n",
    "df_sub = label_3_data(df_sub)\n",
    "df_sub = df_sub.map(lambda x : remove_stopwords(x))\n",
    "df_sub_type = tfvect.transform(df_sub)\n",
    "df_sub_dtm = pd.DataFrame(df_sub_type.toarray(), columns=vocab)\n",
    "\n",
    "y_pred = model.predict(df_sub_dtm)\n",
    "\n",
    "# (y_test == y_pred).mean()\n",
    "\n",
    "# 과거 - 미래 - 현재\n",
    "\n",
    "y_predict = pd.DataFrame(y_pred)\n",
    "\n",
    "# 원핫인코딩 값 되돌리는 함수\n",
    "def one_hot_back(y_predict):\n",
    "    y_predict[\"시제\"] = None\n",
    "    for i in range(len(y_predict[\"시제\"])):\n",
    "        if y_predict.loc[i, 0] == 1:\n",
    "            y_predict.loc[i, \"시제\"] = \"과거\"\n",
    "        if y_predict.loc[i, 1] == 1:\n",
    "            y_predict.loc[i, \"시제\"] = \"미래\"\n",
    "        if y_predict.loc[i, 2] == 1:\n",
    "            y_predict.loc[i, \"시제\"] = \"현재\"\n",
    "\n",
    "    return y_predict\n",
    "\n",
    "Answer_3 = one_hot_back(y_predict)\n",
    "Answer_3 = Answer_3[\"시제\"]\n",
    "Answer_3\n",
    "# df_3_y\n",
    "# (y_test == y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1be5716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 무조건 fit을 해주어서 숫자 연결고리를 맞춰놔야함\\n\\nmax_length = 500\\nvocab_size = 1000\\noov_tok = \"<oov>\"\\ntokenizer = Tokenizer(num_words=vocab_size, oov_token = oov_tok)\\ntokenizer.fit_on_texts(df_3)\\ntrain_sequence = tokenizer.texts_to_sequences(df_3)\\n# test_sequence = tokenizer.texts_to_sequences(X_test)\\npadding_type = \"post\"\\nX_train_sp = pad_sequences(train_sequence, maxlen=500, padding=padding_type)\\n# X_train_sp.shape\\n\\nembedding_dim = 64\\nn_class = y_train.shape[1]\\n\\nX_train, X_test, y_train, y_test = train_test_split(X_train_sp, df_3_y, random_state=42, \\n                                                   stratify=df_3_y, test_size=0.1)\\n\\n# 입력층\\nmodel = Sequential()\\nmodel.add(Embedding(input_dim=vocab_size, \\n                    output_dim=embedding_dim, \\n                    input_length=max_length))\\nmodel.add(Bidirectional(LSTM(units=64, return_sequences=True)))\\nmodel.add(Bidirectional(LSTM(units=32)))\\nmodel.add(Dense(units=16))\\n# 출력층\\nmodel.add(Dense(units=n_class, activation=\"softmax\"))\\n# model.summary()\\n\\n# 컴파일\\nmodel.compile(optimizer=\"adam\", \\n              loss=\"categorical_crossentropy\", \\n              metrics=\"accuracy\")\\n\\nearly_stop = EarlyStopping(monitor=\\'val_loss\\', patience=5)\\nhistory = model.fit(X_train, y_train, \\n                    validation_data=(X_test, y_test), \\n                    epochs=100, callbacks=[early_stop])\\n\\ndf_hist = pd.DataFrame(history.history)\\ndf_hist\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 무조건 fit을 해주어서 숫자 연결고리를 맞춰놔야함\n",
    "\n",
    "max_length = 500\n",
    "vocab_size = 1000\n",
    "oov_tok = \"<oov>\"\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token = oov_tok)\n",
    "tokenizer.fit_on_texts(df_3)\n",
    "train_sequence = tokenizer.texts_to_sequences(df_3)\n",
    "# test_sequence = tokenizer.texts_to_sequences(X_test)\n",
    "padding_type = \"post\"\n",
    "X_train_sp = pad_sequences(train_sequence, maxlen=500, padding=padding_type)\n",
    "# X_train_sp.shape\n",
    "\n",
    "embedding_dim = 64\n",
    "n_class = y_train.shape[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_sp, df_3_y, random_state=42, \n",
    "                                                   stratify=df_3_y, test_size=0.1)\n",
    "\n",
    "# 입력층\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                    output_dim=embedding_dim, \n",
    "                    input_length=max_length))\n",
    "model.add(Bidirectional(LSTM(units=64, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(units=32)))\n",
    "model.add(Dense(units=16))\n",
    "# 출력층\n",
    "model.add(Dense(units=n_class, activation=\"softmax\"))\n",
    "# model.summary()\n",
    "\n",
    "# 컴파일\n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\", \n",
    "              metrics=\"accuracy\")\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=100, callbacks=[early_stop])\n",
    "\n",
    "df_hist = pd.DataFrame(history.history)\n",
    "df_hist\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a20d11f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       확실\n",
       "1       확실\n",
       "2       확실\n",
       "3       확실\n",
       "4       확실\n",
       "        ..\n",
       "7085    확실\n",
       "7086    확실\n",
       "7087    확실\n",
       "7088    확실\n",
       "7089    확실\n",
       "Name: 확실성, Length: 7090, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"확실성\" 컬럼 해결\n",
    "\n",
    "df_4 = train[\"문장\"]\n",
    "\n",
    "# text 자리에 train[\"문장\"]\n",
    "# 문장 전처리 함수\n",
    "def label_4_data(text):\n",
    "    # 전부 소문자 처리\n",
    "    text = text.map(lambda x : x.lower())\n",
    "    # 한글, 영어, 공백, % 제외하고 전부 삭제\n",
    "    text = text.map(lambda x : re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", x))\n",
    "    # 공백 여러 개 삭제\n",
    "    text = text.map(lambda x : re.sub(\"[\\s]\", \" \", x))\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_4 = label_4_data(df_4)\n",
    "\n",
    "\n",
    "# 불용어 제거\n",
    "def remove_stopwords(text):\n",
    "    tokens = text.split(' ')\n",
    "    stops = [\"정부가\", \"정부는\", \"정부에서\", \"이\", \"같은\", \"함께\", \"주\", \"이어\", \n",
    "            \"앞으로\", \"이번\", \"저번\", \"즉시\", \"이같은\", \"년\", \"월\", \"일\", \"및\", \"더\", \n",
    "            \"마치\", \"그리고\", \"그러나\", \"하지만\", \"시\", \"분\", \"초\", \"미국은\", \"미국의\", \"그래도\", \n",
    "            \"미국\", \"중국\", \"중국은\", \"중국의\", \"또\", \"또한\", \"그\", \"그래야\", \"오는\", \"이외\", \n",
    "            \"서울\", \"서울은\", \"서울의\", \"서울이\", \"서울에서\", \"한국\", \"한국형\", \"한국은\", \n",
    "            \"한국의\", \"총\", \"개\", \"등\", \"서울시는\", \"서울시\", \"서울시에서\", \"수출\", \"수입\", \"국가의\", \"국가\", \"국가는\"]\n",
    "    meaningful_words = [w for w in tokens if not w in stops]\n",
    "    \n",
    "    return ' '.join(meaningful_words)\n",
    "\n",
    "df_4 = df_4.map(lambda x : remove_stopwords(x))\n",
    "\n",
    "df_4_y = train[label_4]\n",
    "df_4_y = pd.get_dummies(df_4_y)\n",
    "\n",
    "\n",
    "# TF-IDF로 적용 / min은 %가 값이 두개 잡히는 경계를 기준\n",
    "# max는 지니계수의 개념과 같이 생각하면 0.5 정도가 적당하다고 판단\n",
    "tfvect = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 3), min_df=0.01, max_df=0.5)\n",
    "df_4_type = tfvect.fit_transform(df_4)\n",
    "vocab = tfvect.get_feature_names_out()\n",
    "df_dtm = pd.DataFrame(df_4_type.toarray(), columns=vocab)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_dtm, df_4_y, random_state=42, \n",
    "                                                   stratify=df_4_y, test_size=0.1)\n",
    "# X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "df_sub = test[\"문장\"]\n",
    "df_sub = label_4_data(df_sub)\n",
    "df_sub = df_sub.map(lambda x : remove_stopwords(x))\n",
    "df_sub_type = tfvect.transform(df_sub)\n",
    "df_sub_dtm = pd.DataFrame(df_sub_type.toarray(), columns=vocab)\n",
    "\n",
    "y_pred = model.predict(df_sub_dtm)\n",
    "\n",
    "# (y_test == y_pred).mean()\n",
    "\n",
    "# 불확실 - 확실\n",
    "\n",
    "y_predict = pd.DataFrame(y_pred)\n",
    "\n",
    "# 원핫인코딩 값 되돌리는 함수\n",
    "def one_hot_back(y_predict):\n",
    "    y_predict[\"확실성\"] = None\n",
    "    for i in range(len(y_predict[\"확실성\"])):\n",
    "        if y_predict.loc[i, 0] == 1:\n",
    "            y_predict.loc[i, \"확실성\"] = \"불확실\"\n",
    "        if y_predict.loc[i, 1] == 1:\n",
    "            y_predict.loc[i, \"확실성\"] = \"확실\"\n",
    "            \n",
    "    return y_predict\n",
    "\n",
    "Answer_4 = one_hot_back(y_predict)\n",
    "Answer_4 = Answer_4[\"확실성\"]\n",
    "Answer_4\n",
    "# (y_test == y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ece12f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7085</th>\n",
       "      <td>TEST_7085</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>TEST_7086</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087</th>\n",
       "      <td>TEST_7087</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>TEST_7088</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7089</th>\n",
       "      <td>TEST_7089</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7090 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID         label\n",
       "0     TEST_0000  사실형-긍정-현재-확실\n",
       "1     TEST_0001  사실형-긍정-현재-확실\n",
       "2     TEST_0002  사실형-긍정-과거-확실\n",
       "3     TEST_0003  사실형-긍정-현재-확실\n",
       "4     TEST_0004  사실형-긍정-과거-확실\n",
       "...         ...           ...\n",
       "7085  TEST_7085  사실형-긍정-현재-확실\n",
       "7086  TEST_7086  사실형-긍정-현재-확실\n",
       "7087  TEST_7087  사실형-긍정-현재-확실\n",
       "7088  TEST_7088  사실형-긍정-현재-확실\n",
       "7089  TEST_7089  사실형-긍정-현재-확실\n",
       "\n",
       "[7090 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(sub[\"label\"])):\n",
    "    sub.loc[i, \"label\"] = f\"{Answer_1[i]}-{Answer_2[i]}-{Answer_3[i]}-{Answer_4[i]}\"\n",
    "    \n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbed0d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee464c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa087c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
